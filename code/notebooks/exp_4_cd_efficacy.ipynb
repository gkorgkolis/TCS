{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ae44731",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils import custom_binary_metrics\n",
    "from cd_methods.DynoTears.utils import estimate_with_DYNOTEARS\n",
    "\n",
    "from simulation.simulation_tools import get_optimal_sim_XY\n",
    "\n",
    "from CausalTime.tools import generate_CT\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "COL_NAMES = list(string.ascii_uppercase) + [\"\".join(a) for a in list(itertools.permutations(list(string.ascii_uppercase), r=2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bd5198",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2378c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_dir = Path(os.getcwd()).parents[1].as_posix() \n",
    "save_dir = f\"{par_dir}/data/results/cd_efficacy\"\n",
    "FN = \"cp_style\"\n",
    "\n",
    "\n",
    "# Data structure is as such for convenient comparison with CausalTime\n",
    "DATA_DICT = {\n",
    "\n",
    "    # # NOTE: uncomment for MvTS real data\n",
    "    # filename.split(\".csv\")[0]: {\n",
    "    #     'data_path': f\"{par_dir}/data/MvTS/{FN}/\",\n",
    "    #     'data_type': 'fmri',\n",
    "    #     'task': filename, \n",
    "    #     'straight_path': f\"{par_dir}/data/MvTS/{FN}/\" + f\"{filename}\"\n",
    "    # } for filename in os.listdir(f\"{par_dir}/data/MvTS/{FN}/\")\n",
    "\n",
    "    # # NOTE: uncomment for the rest data\n",
    "    filename.split(\".csv\")[0]: {\n",
    "        'data_path': f\"{par_dir}/data/{FN}/increasing_edges_cp_1/data\",\n",
    "        'data_type': 'fmri',\n",
    "        'task': filename, \n",
    "        'straight_path': f\"{par_dir}/data/{FN}/increasing_edges_cp_1/data/\" + f\"{filename}\"\n",
    "    } for filename in os.listdir(f\"{par_dir}/data/{FN}/increasing_edges_cp_1/data\")\n",
    "}\n",
    "\n",
    "# CausalTime Parameters\n",
    "PARAMS = {\n",
    "    \"batch_size\" : 32, \n",
    "    \"hidden_size\" : 128, \n",
    "    \"num_layers\" : 2, \n",
    "    \"dropout\" : 0.1, \n",
    "    \"seq_length\" : 20, \n",
    "    \"test_size\" : 0.2, \n",
    "    \"learning_rate\" : 0.0001, \n",
    "    \"n_epochs\" : 1, \n",
    "    \"flow_length\" : 4, \n",
    "    \"gen_n\" : 20, \n",
    "    \"n\" : 2000,\n",
    "    \"arch_type\" : \"MLP\", \n",
    "    \"save_path\" : \"outputs/\", \n",
    "    \"log_dir\" : \"log/\", \n",
    "}\n",
    "\n",
    "\n",
    "for k, v in list(DATA_DICT.items())[:10]:\n",
    "\n",
    "    try:\n",
    "    \n",
    "        # info\n",
    "        filename = v['task']\n",
    "        print(f\" \\n------------- {filename} ---------------\\n \")\n",
    "\n",
    "        # data\n",
    "        true_data = pd.read_csv(v[\"straight_path\"])\n",
    "        true_data = true_data.rename(columns=dict(zip(true_data.columns, COL_NAMES[:true_data.shape[1]])))\n",
    "        \n",
    "        # adjust timesteps for computation time \n",
    "        print(f\"true data length: {true_data.shape[0]}\")\n",
    "\n",
    "        # shorten true data\n",
    "        if true_data.shape[0]>2000:\n",
    "            anchor = np.random.uniform(low=0, high=true_data.shape[0]-2000)\n",
    "            true_data = true_data.loc[anchor : anchor + 2000, :]\n",
    "            print(f\"true data length (adjusted): {true_data.shape[0]}\")\n",
    "\n",
    "        # \\epsilon added to avoid computation errors w/ PCMCI\n",
    "        for i in range(true_data.shape[0]):\n",
    "            for j in range(true_data.shape[1]):\n",
    "                if true_data.iloc[i, j] == 0:\n",
    "                    true_data.iloc[i, j] += np.random.uniform(low=0.0001, high=0.001)\n",
    "        \n",
    "\n",
    "        \"\"\" ____________________________________ Simulate w/ TCS ____________________________________ \"\"\"\n",
    "\n",
    "        results_tcs = get_optimal_sim_XY(true_data=true_data)\n",
    "        tcs_data = results_tcs[\"optimal_data\"]\n",
    "        tcs_auc = results_tcs[\"auc\"]\n",
    "\n",
    "\n",
    "        print(\"\"\"\\n ____________________________________ Simulate w/ CausalTime ____________________________________ \\n\"\"\")\n",
    "\n",
    "        true_pd, pro_true_pd, skimmed_pd, pro_gen_pd = generate_CT(\n",
    "                batch_size=PARAMS[\"batch_size\"], \n",
    "                hidden_size=PARAMS[\"hidden_size\"], \n",
    "                num_layers=PARAMS[\"num_layers\"], \n",
    "                dropout=PARAMS[\"dropout\"], \n",
    "                seq_length=PARAMS[\"seq_length\"], \n",
    "                test_size=PARAMS[\"test_size\"], \n",
    "                learning_rate=PARAMS[\"learning_rate\"], \n",
    "                n_epochs=PARAMS[\"n_epochs\"], \n",
    "                flow_length=PARAMS[\"flow_length\"], \n",
    "                gen_n=PARAMS[\"gen_n\"], \n",
    "                n=PARAMS[\"n\"],\n",
    "                arch_type=PARAMS[\"arch_type\"], \n",
    "                save_path=PARAMS[\"save_path\"], \n",
    "                log_dir=PARAMS[\"log_dir\"], \n",
    "                data_path=v[\"data_path\"],\n",
    "                data_type= v[\"data_type\"], \n",
    "                task= v[\"task\"],\n",
    "            )\n",
    "        ct_data = pro_gen_pd.copy()\n",
    "\n",
    "        # Store\n",
    "        os.makedirs(f\"{save_dir}/simulated_tcs/{FN}/\", exist_ok=True)\n",
    "        tcs_data.to_csv(f\"{save_dir}/simulated_tcs/{FN}/{filename}\", index=False)\n",
    "        os.makedirs(f\"{save_dir}/simulated_ct/{FN}/\", exist_ok=True)\n",
    "        ct_data.to_csv(f\"{save_dir}/simulated_ct/{FN}/{filename}\", index=False)\n",
    "        \n",
    "    \n",
    "    except:\n",
    "        print(f\"LOG: CD Efficacy: Error occured when simulating from {FN}.\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d8e48",
   "metadata": {},
   "source": [
    "### CD Efficacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31299b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_paths = {\n",
    "    'air_quality_mini' : Path(os.getcwd()).parents[1] / \"data\" / \"MvTS\" / \"air_quality_mini\",\n",
    "    'AirQualityUCI' : Path(os.getcwd()).parents[1] / \"data\" / \"MvTS\" / \"AirQualityUCI\",\n",
    "    'bike-usage' : Path(os.getcwd()).parents[1] / \"data\" / \"MvTS\" / \"bike-usage\",\n",
    "    'cp_style' : Path(os.getcwd()).parents[1] / \"data\" / \"cp_style\" / \"increasing_edges_cp_1\" / \"data\",\n",
    "    'outdoor' : Path(os.getcwd()).parents[1] / \"data\" / \"MvTS\" / \"outdoor\",\n",
    "    'ETTh1' : Path(os.getcwd()).parents[1] / \"data\" / \"MvTS\" / \"ETTh1\",\n",
    "    'ETTm1' : Path(os.getcwd()).parents[1] / \"data\" / \"MvTS\" / \"ETTm1\",\n",
    "    'fMRI' : Path(os.getcwd()).parents[1] / \"data\" / \"fMRI\" / \"timeseries\",\n",
    "    'WTH' : Path(os.getcwd()).parents[1] / \"data\" / \"MvTS\" / \"WTH\"\n",
    "}\n",
    "\n",
    "sim_path = Path(os.getcwd()).parents[1] / \"data\" / \"results\" / \"cd_efficacy\"\n",
    "\n",
    "res_ct = {}\n",
    "res_tcs = {}\n",
    "res_both = {}\n",
    "\n",
    "for FN in ori_paths.keys():\n",
    "\n",
    "    res_ct[FN] = {}\n",
    "    res_tcs[FN] = {}\n",
    "    res_both[FN] = {}\n",
    "\n",
    "    print(FN)\n",
    "    for k in os.listdir(ori_paths[FN]):\n",
    "        try:\n",
    "            true_data = pd.read_csv(ori_paths[FN] / k)\n",
    "            true_data = true_data.rename(columns=dict(zip(true_data.columns, COL_NAMES[:true_data.shape[1]])))\n",
    "            tcs_data = pd.read_csv(sim_path / \"simulated_tcs\" / FN / k)\n",
    "            ct_data = pd.read_csv(sim_path / \"simulated_ct\" / FN / k)\n",
    "\n",
    "            # Fix potential length mismatches\n",
    "            assert ct_data.shape == tcs_data.shape, AssertionError(\"Different data shape for TCS and CausalTime.\")\n",
    "            if true_data.shape[0] > tcs_data.shape[0]:\n",
    "                true_data = true_data[:tcs_data.shape[0]]\n",
    "            elif true_data.shape[0] < tcs_data.shape[0]:\n",
    "                tcs_data = tcs_data[:true_data.shape[0]]\n",
    "                ct_data = ct_data[:true_data.shape[0]]\n",
    "\n",
    "            print(f\"- {k}\")\n",
    "            print(f\"    - {(tcs_data == ct_data).prod().prod()}\")\n",
    "\n",
    "            adj_cp_true, adj_pd_true = estimate_with_DYNOTEARS(true_data=true_data)\n",
    "            adj_cp_tcs, adj_pd_tcs = estimate_with_DYNOTEARS(true_data=tcs_data)\n",
    "            adj_cp_ct, adj_pd_ct = estimate_with_DYNOTEARS(true_data=ct_data)\n",
    "\n",
    "            tpr, fpr, tnr, fnr, auc = custom_binary_metrics(torch.tensor(adj_cp_tcs), torch.tensor(adj_cp_true), verbose=False)\n",
    "            res_tcs[FN][k] = auc.item()\n",
    "\n",
    "            tpr, fpr, tnr, fnr, auc = custom_binary_metrics(torch.tensor(adj_cp_ct), torch.tensor(adj_cp_true), verbose=False)\n",
    "            res_ct[FN][k] = auc.item()\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    res_both[FN][\"TCS_mean\"] = np.array(list(res_tcs[FN].values())).mean().round(2)\n",
    "    res_both[FN][\"CT_mean\"] = np.array(list(res_ct[FN].values())).mean().round(2)\n",
    "    res_both[FN][\"TCS_var\"] = np.array(list(res_tcs[FN].values())).var().round(2)\n",
    "    res_both[FN][\"CT_var\"] = np.array(list(res_ct[FN].values())).var().round(2)\n",
    "    \n",
    "pd.DataFrame(data=res_both).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
